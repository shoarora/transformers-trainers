model:
  generator_name: electra_small_generator
  discriminator_name: electra_small_discriminator
  tokenizer_path: bert-base-uncased

  training:
    total_steps: ${trainer.max_steps}

data:
  dataset_path: wikipedia
  dataset_version: 20200501.en
  batch_size: 32
  num_workers: 4
  column: text
  block_size: null
  mlm_probability: 0.15

trainer:
  gpus: 0
  fast_dev_run: false
  max_steps: 1e6
  limit_val_batches: 0.1
  val_check_interval: 0.1

logger:
  type: wandb
  args: null
